# ===========================================
# Step 1. è¼‰å…¥å¥—ä»¶èˆ‡ä¸­æ–‡å­—é«”è¨­å®š
# ===========================================
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split # åŠƒåˆ†æ•¸æ“šé›†
from sklearn.feature_selection import mutual_info_classif # æ–°å¢ï¼šç”¨æ–¼è¨ˆç®—äº’ä¿¡æ¯
import matplotlib.pyplot as plt # åƒ…ç”¨æ–¼é¡¯ç¤ºåœ–è¡¨ (å¦‚æœéœ€è¦)
import seaborn as sns
import os
# from matplotlib.backends.backend_pdf import PdfPages # å·²ç§»é™¤ PDF åŒ¯å…¥
from openpyxl import load_workbook # Excel å¯«å…¥å¥—ä»¶

# --- ä¸­æ–‡å­—é«”è¨­å®š (è§£æ±ºåœ–è¡¨ä¸­æ–‡é¡¯ç¤ºå•é¡Œ) ---
# å˜—è©¦è¨­å®šå„ªå…ˆä½¿ç”¨å¾®è»Ÿæ­£é»‘é«”ï¼Œå¦å‰‡ä½¿ç”¨é è¨­
plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'DejaVu Sans', 'Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False # è§£æ±ºè² è™Ÿ'-'é¡¯ç¤ºç‚ºæ–¹å¡Šçš„å•é¡Œ
print("âœ… Matplotlib ä¸­æ–‡å­—é«”è¨­å®šå®Œæˆã€‚")

# ===========================================
# Step 2. è³‡æ–™è¼‰å…¥
# ===========================================
print("\n--- 2. è³‡æ–™è¼‰å…¥ ---")
# å˜—è©¦å¾æ¡Œé¢è®€å– Excel
desktop_path = os.path.expanduser("~/Desktop/data.xlsx")

if os.path.exists(desktop_path):
    print("âœ… æª”æ¡ˆå­˜åœ¨ï¼Œä½¿ç”¨ pd.read_excel è®€å–è³‡æ–™ (æ¡Œé¢)...")
    df = pd.read_excel(desktop_path)
    # è¨­å®š Excel è¼¸å‡ºè·¯å¾‘
    excel_output_path = os.path.expanduser("~/Desktop/Ocular_Disease_Data_and_Results.xlsx")
else:
    print("âŒ æ‰¾ä¸åˆ°æœ¬åœ° data.xlsx (æ¡Œé¢)ï¼Œå˜—è©¦è¼‰å…¥ä¸Šå‚³çš„æª”æ¡ˆ 'data.xlsx - Sheet1.csv'ã€‚")
    try:
        # å˜—è©¦ç”¨ utf-8 è®€å– CSV
        df = pd.read_csv('data.xlsx - Sheet1.csv', encoding='utf-8')
    except:
        # å˜—è©¦ç”¨ gbk è®€å– CSV
        df = pd.read_csv('data.xlsx - Sheet1.csv', encoding='gbk')
    print("âœ… æª”æ¡ˆå·²è®€å–ã€‚è«‹æ³¨æ„ï¼šç”±æ–¼æœªæ‰¾åˆ°æ¡Œé¢ Excelï¼Œåˆ†æçµæœå°‡å„²å­˜åˆ°ä¸€å€‹æ¨¡æ“¬çš„ Excel è·¯å¾‘ã€‚")
    excel_output_path = os.path.expanduser("~/Desktop/Ocular_Disease_Data_and_Results.xlsx")


print(f"ğŸ“Š è¼‰å…¥è³‡æ–™ç­†æ•¸ï¼š{len(df)} ç­†")

# åŸå§‹ç¨‹å¼ç¢¼ä¸­çš„éæ¿¾æ¢ä»¶
df = df[df["N"] == 0]
print("âœ… ç¯©é¸ 'N = 0' å¾Œçš„è³‡æ–™ç­†æ•¸:", len(df))

# å®šç¾©ç–¾ç—…æ¬„ä½ï¼Œç¢ºä¿å¾ŒçºŒæ­¥é©Ÿä½¿ç”¨çš„æ¬„ä½ä¸€è‡´
disease_cols = ["N", "D", "G", "C", "A", "H", "M", "O"]


# ===========================================
# Step 3. ç¼ºå¤±å€¼è™•ç†
# ===========================================
print("\n--- 3. ç¼ºå¤±å€¼è™•ç† ---")
# å¹´é½¡ç”¨å¹³å‡å€¼è£œï¼Œç–¾ç—…æ¬„ä½ç¼ºå¤±è¦–ç‚º0
df["Patient Age"] = df["Patient Age"].fillna(df["Patient Age"].mean())

for col in disease_cols:
    df[col] = df[col].fillna(0)


# ===========================================
# Step 4. ç•°å¸¸å€¼è™•ç† (ä»¥å¹³å‡æ•¸ Â± 3*æ¨™æº–å·®åµæ¸¬å¹´é½¡æ¥µç«¯å€¼)
# ===========================================
print("\n--- 4. å¹´é½¡ç•°å¸¸å€¼è™•ç† ---")
mean_age = df["Patient Age"].mean()
std_age = df["Patient Age"].std()

lower = mean_age - 3 * std_age
upper = mean_age + 3 * std_age

df = df[(df["Patient Age"] >= lower) & (df["Patient Age"] <= upper)]
print("âœ… ç§»é™¤ç•°å¸¸å€¼å¾Œç­†æ•¸:", len(df))

# é‡æ–°è¨ˆç®—çµ±è¨ˆé‡ (ç”¨æ–¼å ±å‘Š)
mean_age = df["Patient Age"].mean()
std_age = df["Patient Age"].std()

print(f"ğŸ‘‰ ç®—è¡“å¹³å‡æ•¸(mean):{mean_age:.2f}")
print(f"ğŸ‘‰ æ¨™æº–å·®(std):{std_age:.2f}")


# ===========================================
# Step 5. ç·¨ç¢¼è™•ç†(ä¿è­‰0èˆ‡1)
# ===========================================
print("\n--- 5. ç–¾ç—…æ¬„ä½ç·¨ç¢¼ ---")
for col in disease_cols:
    df[col] = df[col].apply(lambda x: 1 if x == 1 else 0)


# ===========================================
# Step 6. æ•¸æ“šé›†åŠƒåˆ† (è¨“ç·´é›†/æ¸¬è©¦é›† 80/20)
# ===========================================
print("\n--- 6. æ•¸æ“šé›†åŠƒåˆ† (è¨“ç·´é›†/æ¸¬è©¦é›† 80/20) ---")

# ç‰¹å¾µ (X): ä½¿ç”¨å°šæœªæ¨™æº–åŒ–çš„ Patient Age ä½œç‚ºä¸»è¦æ•¸å€¼ç‰¹å¾µ
X_pre_split = df[['Patient Age']].copy() 

# ç›®æ¨™è®Šæ•¸ (Y): ç–¾ç—…ä»£è™Ÿ (D, G, C, A, H, M, O)
analysis_cols = [col for col in disease_cols if col != "N"]
Y_pre_split = df[analysis_cols].copy() 

# åŠƒåˆ†æ•¸æ“šé›†
X_train, X_test, y_train, y_test = train_test_split(
    X_pre_split, 
    Y_pre_split, 
    test_size=0.2,       # èª¿æ•´ç‚º 20% ç‚ºæ¸¬è©¦é›†
    random_state=42,     # å›ºå®šç¨®å­ç¢ºä¿çµæœå¯é‡ç¾
    shuffle=True         # é è¨­ç‚º True
)

print(f"âœ… è¨“ç·´é›†å¤§å°: {len(X_train)} ç­† (80%)")
print(f"âœ… æ¸¬è©¦é›†å¤§å°: {len(X_test)} ç­† (20%)")


# ===========================================
# Step 7. æ­¸ä¸€åŒ–è™•ç†(å°‡å¹´é½¡æ¨™æº–åŒ–) <--- æ¨™æº–åŒ–ç§»åˆ°åŠƒåˆ†ä¹‹å¾Œ
# ===========================================
print("\n--- 7. å¹´é½¡æ¨™æº–åŒ– (Z-score) ---")
scaler = StandardScaler()

# 1. å°å®Œæ•´ df é€²è¡Œæ¨™æº–åŒ– (ç”¨æ–¼å¾ŒçºŒ EDA æ­¥é©Ÿ 10, 11, 12 çš„ç†±åŠ›åœ–/ç›¸é—œæ€§åˆ†æ)
# æ³¨æ„ï¼šé€™æœƒè®“ EDA ä½¿ç”¨çš„ df ç”¢ç”Ÿæ•¸æ“šæ´©éœ²ï¼Œä½†é€™æ˜¯ç‚ºäº†æ–¹ä¾¿ EDA è¦–è¦ºåŒ–ã€‚
df["Patient Age_z"] = scaler.fit_transform(df[["Patient Age"]])
print("è¨» 1: å®Œæ•´æ•¸æ“šé›†çš„æ¨™æº–åŒ– (df['Patient Age_z']) å·²å®Œæˆï¼Œç”¨æ–¼ EDAã€‚")


# 2. å° X_train/X_test é€²è¡Œæ¨™æº–åŒ– (ç”¨æ–¼ ML æ¨¡å‹)
# **é—œéµï¼šåªç”¨ X_train fit scalerï¼Œç„¶å¾Œ transform X_test**
scaler_ml = StandardScaler()
X_train_scaled = scaler_ml.fit_transform(X_train)
X_test_scaled = scaler_ml.transform(X_test)

# X_train_scaled, X_test_scaled, y_train, y_test å·²æº–å‚™å¥½ç”¨æ–¼æ©Ÿå™¨å­¸ç¿’æ¨¡å‹è¨“ç·´ã€‚
print("è¨» 2: è¨“ç·´é›†ç‰¹å¾µ (X_train_scaled) å’Œæ¸¬è©¦é›†ç‰¹å¾µ (X_test_scaled) å·²å®Œæˆæ¨™æº–åŒ–ï¼Œç„¡æ•¸æ“šæ´©éœ²ï¼Œç”¨æ–¼æ¨¡å‹è¨“ç·´ã€‚")


# ===========================================
# Step 8. å¹´é½¡åˆ†çµ„
# ===========================================
print("\n--- 8. å¹´é½¡åˆ†çµ„ ---")
def age_group(age):
    if 0 <= age <= 14:
        return 'Juvenile (0-14)'
    elif 15 <= age <= 64:
        return 'Adult (15-64)'
    else: # age >= 65
        return 'Elderly (65+)'

# å»ºç«‹æ–°çš„å¹´é½¡çµ„åˆ¥æ¬„ä½
df['Age_Group'] = df['Patient Age'].apply(age_group)

print("âœ… å¹´é½¡åˆ†çµ„çµæœçµ±è¨ˆ:")
print(df['Age_Group'].value_counts().sort_index().to_markdown())


# ===========================================
# Step 9. ç›¸é—œä¿‚æ•¸åˆ†æèˆ‡ç†±åŠ›åœ– (æ•´é«”æ•¸æ“š)
# ===========================================
print("\n--- 9. æ•¸å€¼ç‰¹å¾µç›¸é—œä¿‚æ•¸åˆ†æ (é€£çºŒå¹´é½¡) ---")
# åªå–æ•¸å€¼å‹æ¬„ä½
num_df = df.select_dtypes(include='number')

# æ’é™¤ ID èˆ‡åŸå§‹ Patient Age (Patient Age_z æ‡‰ä¿ç•™)
try:
    num_df = num_df.drop(columns=['ID', 'Patient Age'])
except KeyError:
    num_df = num_df.drop(columns=['Patient Age'], errors='ignore')

# è¨ˆç®—çš®çˆ¾æ£®ç›¸é—œä¿‚æ•¸
corr = num_df.corr()

# ç•«ç†±åŠ›åœ– (åªé¡¯ç¤ºï¼Œä¸å„²å­˜åˆ° PDF)
fig_9 = plt.figure(figsize=(10, 8)) 
sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Feature Correlation Heatmap (Overall Data)") 
plt.tight_layout()
# ç§»é™¤ pdf_pages.savefig(fig_9)
plt.show() # æ–°å¢ï¼šåŸ·è¡Œæ™‚é¡¯ç¤ºåœ–è¡¨
plt.close(fig_9) 


# ===========================================
# Step 10. å¹´é½¡çµ„åˆ¥èˆ‡ç–¾ç—…ç™¼ç”Ÿç‡äº¤å‰åˆ†æ (å¹´é½¡å±¤å·®ç•°)
# ===========================================
print("\n--- 10. å¹´é½¡çµ„åˆ¥ vs. ç–¾ç—…ç™¼ç”Ÿç‡åˆ†æ ---")

# åŸ·è¡Œåˆ†çµ„èšåˆï¼šè¨ˆç®—æ¯å€‹å¹´é½¡çµ„åˆ¥ä¸­ï¼Œæ¯å€‹ç–¾ç—…çš„å¹³å‡å€¼ (å³ç™¼ç”Ÿç‡)
# analysis_cols å·²åœ¨ Step 6 å®šç¾©
age_disease_crosstab = df.groupby('Age_Group')[analysis_cols].mean().reset_index()

# è¨­å®šå¹´é½¡çµ„åˆ¥çš„é¡¯ç¤ºé †åº
group_order = ['Juvenile (0-14)', 'Adult (15-64)', 'Elderly (65+)']
age_disease_crosstab['Age_Group'] = pd.Categorical(
    age_disease_crosstab['Age_Group'],
    categories=group_order,
    ordered=True
)
age_disease_crosstab = age_disease_crosstab.sort_values('Age_Group')

print("\nâœ… å¹´é½¡çµ„åˆ¥ vs. ç–¾ç—…å¹³å‡ç™¼ç”Ÿç‡ (0~1):")
print(age_disease_crosstab.to_markdown(index=False, floatfmt=".3f"))


# --- è¦–è¦ºåŒ–å¹´é½¡çµ„åˆ¥å½±éŸ¿ (Bar Plot) ---
melted_df = age_disease_crosstab.melt(
    id_vars='Age_Group',
    value_vars=analysis_cols,
    var_name='Disease_Code',
    value_name='Prevalence'
)

fig_10 = plt.figure(figsize=(12, 6)) 
sns.barplot(
    data=melted_df,
    x='Disease_Code',
    y='Prevalence',
    hue='Age_Group',
    palette='viridis'
)
plt.title('Average Ocular Disease Prevalence by Age Group') 
plt.ylabel('Average Prevalence') 
plt.xlabel('Disease Code (D, G, C, A, H, M, O)') 
plt.legend(title='Age Group') 
plt.grid(axis='y', linestyle='--')
plt.tight_layout()
# ç§»é™¤ pdf_pages.savefig(fig_10) 
plt.show() # æ–°å¢ï¼šåŸ·è¡Œæ™‚é¡¯ç¤ºåœ–è¡¨
plt.close(fig_10) 


# ===========================================
# Step 11. åˆ†çµ„ç›¸é—œä¿‚æ•¸ç†±åŠ›åœ– (æ–°å¢)
# ===========================================
print("\n--- 11. åˆ†çµ„ç›¸é—œä¿‚æ•¸ç†±åŠ›åœ– (åˆ†çµ„å…§å¹´é½¡å½±éŸ¿) ---")

# ç§»é™¤ Patient Age_zï¼Œå› ç‚ºåˆ†çµ„å…§æˆ‘å€‘ä½¿ç”¨åŸå§‹ Patient Age é€²è¡Œç›¸é—œæ€§åˆ†æï¼Œ
# é€™æ¨£æ›´èƒ½åæ˜ è©²å¹´é½¡å±¤å…§å¹´é½¡å¢é•·çš„å¯¦éš›å½±éŸ¿ã€‚
try:
    analysis_df = df.drop(columns=['ID', 'Patient Age_z'], errors='ignore')
except KeyError:
    analysis_df = df.drop(columns=['Patient Age_z'], errors='ignore')
analysis_df = analysis_df.select_dtypes(include=['number', 'object'])


# å®šç¾©è¦ç”Ÿæˆçš„çµ„åˆ¥
group_names = ['Adult (15-64)', 'Elderly (65+)']

fig, axes = plt.subplots(1, 2, figsize=(18, 7))
# è‹±æ–‡ç¸½æ¨™é¡Œ
fig.suptitle('Feature Correlation Heatmap within Age Groups (Patient Age reflects intra-group growth)', y=1.02, fontsize=16) 

for i, group in enumerate(group_names):
    # ç¯©é¸è³‡æ–™
    group_df = analysis_df[analysis_df['Age_Group'] == group]

    # åªä¿ç•™æ•¸å€¼æ¬„ä½ (åŒ…æ‹¬ Patient Age å’Œç–¾ç—…æ¬„ä½)
    num_group_df = group_df.select_dtypes(include='number')

    # è¨ˆç®—çµ„å…§ç›¸é—œä¿‚æ•¸
    group_corr = num_group_df.corr()

    # ç•«ç†±åŠ›åœ–
    sns.heatmap(
        group_corr,
        annot=True,
        cmap='coolwarm',
        fmt=".2f",
        ax=axes[i],
        vmin=-1, # çµ±ä¸€è‰²éšç¯„åœ
        vmax=1
    )
    # è‹±æ–‡å­åœ–æ¨™é¡Œ
    axes[i].set_title(f"Group: {group} (N: {len(group_df)})") 

plt.tight_layout()
# ç§»é™¤ pdf_pages.savefig(fig) 
plt.show() # æ–°å¢ï¼šåŸ·è¡Œæ™‚é¡¯ç¤ºåœ–è¡¨
plt.close(fig) 


# ===========================================
# Step 12. ç‰¹å¾µé¦™è¾²äº‚åº¦ (Shannon Entropy) åˆ†æèˆ‡è¦–è¦ºåŒ–
# ===========================================
print("\n--- 12. ç‰¹å¾µé¦™è¾²äº‚åº¦ (Entropy) åˆ†æ ---")

def calculate_shannon_entropy(series):
    """è¨ˆç®— Pandas Series çš„ Shannon Entropy (åŸºæ•¸ç‚º 2)ã€‚"""
    # é©ç”¨æ–¼äºŒå…ƒ (0/1) ç‰¹å¾µ
    if series.dtype in ['int64', 'float64'] and series.nunique() <= 2:
        # p å³ç‚º 1 çš„ç™¼ç”Ÿç‡ (Prevalence)
        p = series.mean()
        if p == 0 or p == 1:
            return 0.0
        # H(p) = -(p * log2(p) + (1-p) * log2(1-p))
        entropy = - (p * np.log2(p) + (1 - p) * np.log2(1 - p))
        return entropy
    else:
        # é©ç”¨æ–¼å¤šåˆ†é¡ç‰¹å¾µ
        probabilities = series.value_counts(normalize=True)
        # æ’é™¤æ¦‚ç‡ç‚º 0 çš„æƒ…æ³ï¼Œé¿å… log2(0) éŒ¯èª¤
        probabilities = probabilities[probabilities > 0]
        # H(X) = - sum(P(x_i) * log2(P(x_i)))
        entropy = - (probabilities * np.log2(probabilities)).sum()
        return entropy

entropy_results = {}

# 1. åªè¨ˆç®—ç–¾ç—…æ¬„ä½ (äºŒå…ƒç‰¹å¾µ) çš„äº‚åº¦
for col in analysis_cols:
    entropy_results[col] = calculate_shannon_entropy(df[col])

# å°‡çµæœè½‰æ›ç‚º DataFrame ä»¥ä¾¿è¦–è¦ºåŒ–
entropy_df = pd.DataFrame(
    list(entropy_results.items()),
    columns=['Feature', 'Entropy']
)

# æ’åºï¼Œè®“äº‚åº¦æœ€é«˜çš„åœ¨å‰é¢
entropy_df = entropy_df.sort_values(by='Entropy', ascending=False)

print("\nâœ… ç‰¹å¾µé¦™è¾²äº‚åº¦çµæœ:")
print(entropy_df.to_markdown(index=False, floatfmt=".4f"))

# --- è¦–è¦ºåŒ–äº‚åº¦é•·æ¢åœ– ---
fig_12 = plt.figure(figsize=(10, 6)) 
sns.barplot(
    data=entropy_df,
    x='Entropy',
    y='Feature',
    palette='magma'
)
plt.title('Shannon Entropy of Ocular Disease Features (Base 2)', fontsize=16) 
plt.xlabel('Entropy Value (Base 2)') 
plt.ylabel('Disease Feature') 
plt.grid(axis='x', linestyle='--')
plt.tight_layout()
# ç§»é™¤ pdf_pages.savefig(fig_12) 
plt.show() # æ–°å¢ï¼šåŸ·è¡Œæ™‚é¡¯ç¤ºåœ–è¡¨
plt.close(fig_12) 


# ===========================================
# Step 13. å¹´é½¡èˆ‡ç–¾ç—…çš„äº’ä¿¡æ¯ (Mutual Information) åˆ†æ (é€£çºŒå¹´é½¡)
# ===========================================
print("\n--- 13. å¹´é½¡èˆ‡ç–¾ç—…çš„äº’ä¿¡æ¯ (Mutual Information) åˆ†æ ---")

# Mutual Information è¨ˆç®—
# MI è¡¡é‡é€£çºŒçš„ 'Patient Age' (X) å°é æ¸¬äºŒå…ƒç–¾ç—… (Y) èƒ½æä¾›å¤šå°‘ä¿¡æ¯é‡ã€‚
mi_results = {}
X_age = df[['Patient Age']]

print("è¨ˆç®— Patient Age (é€£çºŒ) èˆ‡å„ç–¾ç—… (äºŒå…ƒ) çš„äº’ä¿¡æ¯...")
for col in analysis_cols:
    y_disease = df[col]
    
    # mutual_info_classif é©ç”¨æ–¼é€£çºŒ X å’Œåˆ†é¡ Y
    mi_score = mutual_info_classif(X_age, y_disease, random_state=42)[0]
    mi_results[col] = mi_score

# å°‡çµæœè½‰æ›ç‚º DataFrame ä»¥ä¾¿è¦–è¦ºåŒ–
mi_df = pd.DataFrame(
    list(mi_results.items()),
    columns=['Disease Feature', 'Mutual Information (MI)']
)
mi_df = mi_df.sort_values(by='Mutual Information (MI)', ascending=False)

print("\nâœ… å¹´é½¡èˆ‡ç–¾ç—…äº’ä¿¡æ¯çµæœ:")
print(mi_df.to_markdown(index=False, floatfmt=".4f"))


# --- è¦–è¦ºåŒ–äº’ä¿¡æ¯é•·æ¢åœ– ---
fig_13 = plt.figure(figsize=(10, 6)) 
sns.barplot(
    data=mi_df,
    x='Mutual Information (MI)',
    y='Disease Feature',
    palette='Spectral'
)
plt.title('Mutual Information between Patient Age and Disease Features', fontsize=16) 
plt.xlabel('Mutual Information Value') 
plt.ylabel('Disease Feature') 
plt.grid(axis='x', linestyle='--')
plt.tight_layout()
# ç§»é™¤ pdf_pages.savefig(fig_13) 
plt.show() # æ–°å¢ï¼šåŸ·è¡Œæ™‚é¡¯ç¤ºåœ–è¡¨
plt.close(fig_13) 


# ===========================================
# Step 14. å°‡è™•ç†å¾Œçš„è³‡æ–™å’Œåˆ†æçµæœè¼¸å‡ºåˆ° Excel
# ===========================================
print(f"\n--- 14. å°‡çµæœè¼¸å‡ºåˆ° Excel å ±å‘Š: {excel_output_path} ---")

# é¸æ“‡è¦è¼¸å‡ºçš„æœ€çµ‚æ•¸æ“šæ¬„ä½
cleaned_data_cols = ['Patient Age', 'Patient Age_z', 'Age_Group'] + disease_cols
cleaned_data_df = df[cleaned_data_cols].copy()

# *** ä¿®æ­£ï¼šæ˜ç¢ºæŒ‡å®š engine='openpyxl' ä¾†è§£æ±º ModuleNotFoundError: No module named 'xlsxwriter' ***
with pd.ExcelWriter(excel_output_path, engine='openpyxl') as writer:
    # 1. è™•ç†å¾Œçš„æ•¸æ“šé›†
    cleaned_data_df.to_excel(
        writer, 
        sheet_name='Cleaned Data', 
        index=False,
        float_format="%.4f"
    )
    print("âœ… å·¥ä½œè¡¨ 'Cleaned Data' (è™•ç†å¾Œçš„è³‡æ–™é›†) å¯«å…¥å®Œæˆã€‚")

    # 2. é¦™è¾²äº‚åº¦çµæœ
    entropy_df.to_excel(
        writer, 
        sheet_name='Entropy Results', 
        index=False,
        float_format="%.4f"
    )
    print("âœ… å·¥ä½œè¡¨ 'Entropy Results' (é¦™è¾²äº‚åº¦) å¯«å…¥å®Œæˆã€‚")

    # 3. äº’ä¿¡æ¯çµæœ
    mi_df.to_excel(
        writer, 
        sheet_name='MI Results', 
        index=False,
        float_format="%.4f"
    )
    print("âœ… å·¥ä½œè¡¨ 'MI Results' (å¹´é½¡äº’ä¿¡æ¯) å¯«å…¥å®Œæˆã€‚")

print("ğŸ‰ æ•¸æ“šè™•ç†å’Œåˆ†æçµæœå·²åŒæ­¥è¼¸å‡ºè‡³ Excel æª”æ¡ˆä¸­ã€‚")
